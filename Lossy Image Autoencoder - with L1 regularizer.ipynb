{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lossy image autoencoders - with regularizer\n",
    "\n",
    "Implemented with convolution and deconvolution networks in Tensorflow\n",
    "\n",
    "- Samvram Sahu\n",
    "- Arnab Karmakar\n",
    "\n",
    "Referrence : Giuseppe Bonaccorso (https://www.bonaccorso.eu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python35\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['e', 'beta']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "from numba import jit\n",
    "from keras.datasets import cifar10\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed (for reproducibility)\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 32\n",
    "height = 32\n",
    "batch_size = 10\n",
    "nb_epochs = 15\n",
    "code_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "beta = 0.01\n",
    "\n",
    "with graph.as_default():\n",
    "    # Global step\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    \n",
    "    # Input batch\n",
    "    input_images = tf.placeholder(tf.float32, shape=(batch_size, height, width, 3))\n",
    "\n",
    "    # Convolutional layer 1\n",
    "    conv1 = tf.layers.conv2d(inputs=input_images,\n",
    "                             filters=32,\n",
    "                             kernel_size=(3, 3),\n",
    "                             kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                             activation=tf.nn.tanh)\n",
    "\n",
    "    # Convolutional output (flattened)\n",
    "    conv_output = tf.contrib.layers.flatten(conv1)\n",
    "\n",
    "    # Code layer\n",
    "    code_layer = tf.layers.dense(inputs=conv_output,\n",
    "                                 units=code_length,\n",
    "                                 activation=tf.nn.tanh)\n",
    "    \n",
    "    # Code output layer\n",
    "    code_output = tf.layers.dense(inputs=code_layer,\n",
    "                                  units=(height - 2) * (width - 2) * 3,\n",
    "                                  activation=tf.nn.tanh)\n",
    "\n",
    "    # Deconvolution input\n",
    "    deconv_input = tf.reshape(code_output, (batch_size, height - 2, width - 2, 3))\n",
    "\n",
    "    # Deconvolution layer 1\n",
    "    deconv1 = tf.layers.conv2d_transpose(inputs=deconv_input,\n",
    "                                         filters=3,\n",
    "                                         kernel_size=(3, 3),\n",
    "                                         kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                         activation=tf.sigmoid)\n",
    "    \n",
    "    # Output batch\n",
    "    output_images = tf.cast(tf.reshape(deconv1, \n",
    "                                       (batch_size, height, width, 3)) * 255.0, tf.uint8)\n",
    "\n",
    "    # Obtaining weights for use in regularization\n",
    "    weights = tf.get_default_graph().get_tensor_by_name(os.path.split(code_layer.name)[0] + '/kernel:0')\n",
    "    regularizer = np.sum(np.absolute(weights))\n",
    "    \n",
    "    # Reconstruction L2 loss & L1 reguarization\n",
    "    loss = tf.nn.l2_loss(input_images - deconv1) + beta*regularizer\n",
    "    \n",
    "    # Training operations\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate=0.0005, \n",
    "                                               global_step=global_step, \n",
    "                                               decay_steps=int(X_train.shape[0] / (2 * batch_size)), \n",
    "                                               decay_rate=0.95, \n",
    "                                               staircase=True)\n",
    "    \n",
    "    trainer = tf.train.RMSPropOptimizer(learning_rate)\n",
    "    training_step = trainer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "use_gpu = True\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=multiprocessing.cpu_count(), \n",
    "                        inter_op_parallelism_threads=multiprocessing.cpu_count(), \n",
    "                        allow_soft_placement=True, \n",
    "                        device_count = {'CPU' : 1, \n",
    "                                        'GPU' : 1 if use_gpu else 0})\n",
    "\n",
    "session = tf.InteractiveSession(graph=graph, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def create_batch(t, gray=False):\n",
    "    X = np.zeros((batch_size, height, width, 3 if not gray else 1), dtype=np.float32)\n",
    "        \n",
    "    for k, image in enumerate(X_train[t:t+batch_size]):\n",
    "        if gray:\n",
    "            X[k, :, :, :] = rgb2gray(image)\n",
    "        else:\n",
    "            X[k, :, :, :] = image / 255.0\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(nb_epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for t in range(0, X_train.shape[0], batch_size):\n",
    "        feed_dict = {\n",
    "            input_images: create_batch(t)\n",
    "        }\n",
    "\n",
    "        _, v_loss = session.run([training_step, loss], feed_dict=feed_dict)\n",
    "        total_loss += v_loss\n",
    "        \n",
    "    print('Epoch {} - Total loss: {}'.format(e+1, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    input_images: create_batch(0)\n",
    "}\n",
    "\n",
    "\n",
    "oimages = session.run([output_images], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, batch_size, figsize=(18, 3))\n",
    "\n",
    "for y in range(batch_size):\n",
    "    ax[0, y].get_xaxis().set_visible(False)\n",
    "    ax[0, y].get_yaxis().set_visible(False)\n",
    "    ax[1, y].get_xaxis().set_visible(False)\n",
    "    ax[1, y].get_yaxis().set_visible(False)\n",
    "\n",
    "    ax[0, y].imshow(X_train[y])\n",
    "    ax[1, y].imshow(oimages[0][y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
